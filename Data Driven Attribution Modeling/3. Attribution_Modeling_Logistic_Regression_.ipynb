{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Driven Models\n",
    "\n",
    "\n",
    "Heuristic solutions are inflexible and unable to distinguish between the true low and high impact touch-points, resulting in an inaccurate division of credit.\n",
    "Luckily, there are more sophisticated, data-driven approaches that address these limitations. Data-driven attribution is a custom solution that is able to capture the intricacies of buyer journeys by modelling how channels, and more importantly how different combinations of channels, interact with buyers to influence a desired sales outcome. A data-driven model provides the most accurate view of which channels are performing the best, driving better marketing accountability and efficiency.\n",
    "\n",
    "#### There are various models which can be implemented such as - \n",
    "- Logistic Regression\n",
    "- LSTM\n",
    "- LSTM with Attention\n",
    "- Shapely method and Game Theory\n",
    "- Markov Chain Models\n",
    "\n",
    "We will implement some of these in the next notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'N:\\ALGORITHMIC MARKETING\\Assignment3\\criteo_attribution_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE='criteo_attribution_dataset.tsv.gz'\n",
    "df_Criteo_Attribution = pd.read_csv(DATA_FILE, sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_campaigns = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Criteo_Attribution['day'] = np.floor(df_Criteo_Attribution.timestamp / 86400.).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_derived_columns(df):\n",
    "    df_ext = df.copy()\n",
    "    df_ext['jid'] = df_ext['uid'].map(str) + '_' + df_ext['conversion_id'].map(str)\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    for cname in ('timestamp', 'time_since_last_click'):\n",
    "        x = df_ext[cname].values.reshape(-1, 1) \n",
    "        df_ext[cname + '_norm'] = min_max_scaler.fit_transform(x)\n",
    "    \n",
    "    return df_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Criteo_Attribution = add_derived_columns(df_Criteo_Attribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>uid</th>\n",
       "      <th>campaign</th>\n",
       "      <th>conversion</th>\n",
       "      <th>conversion_timestamp</th>\n",
       "      <th>conversion_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>click</th>\n",
       "      <th>click_pos</th>\n",
       "      <th>click_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>day</th>\n",
       "      <th>jid</th>\n",
       "      <th>timestamp_norm</th>\n",
       "      <th>time_since_last_click_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20073966</td>\n",
       "      <td>22589171</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>29196072</td>\n",
       "      <td>11409686</td>\n",
       "      <td>1973606</td>\n",
       "      <td>25162884</td>\n",
       "      <td>29196072</td>\n",
       "      <td>29196072</td>\n",
       "      <td>0</td>\n",
       "      <td>20073966_-1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>24607497</td>\n",
       "      <td>884761</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>29196072</td>\n",
       "      <td>11409686</td>\n",
       "      <td>1973606</td>\n",
       "      <td>22644417</td>\n",
       "      <td>9312274</td>\n",
       "      <td>21091111</td>\n",
       "      <td>0</td>\n",
       "      <td>24607497_-1</td>\n",
       "      <td>7.487274e-07</td>\n",
       "      <td>0.163526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28474333</td>\n",
       "      <td>18975823</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>29196072</td>\n",
       "      <td>5824237</td>\n",
       "      <td>138937</td>\n",
       "      <td>1795451</td>\n",
       "      <td>29196072</td>\n",
       "      <td>15351056</td>\n",
       "      <td>0</td>\n",
       "      <td>28474333_-1</td>\n",
       "      <td>7.487274e-07</td>\n",
       "      <td>0.003426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7306395</td>\n",
       "      <td>29427842</td>\n",
       "      <td>1</td>\n",
       "      <td>1449193</td>\n",
       "      <td>3063962</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>23549932</td>\n",
       "      <td>5824237</td>\n",
       "      <td>1973606</td>\n",
       "      <td>9180723</td>\n",
       "      <td>29841067</td>\n",
       "      <td>29196072</td>\n",
       "      <td>0</td>\n",
       "      <td>7306395_3063962</td>\n",
       "      <td>1.123091e-06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>25357769</td>\n",
       "      <td>13365547</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>29196072</td>\n",
       "      <td>11409684</td>\n",
       "      <td>26597096</td>\n",
       "      <td>4480345</td>\n",
       "      <td>29196072</td>\n",
       "      <td>29196072</td>\n",
       "      <td>0</td>\n",
       "      <td>25357769_-1</td>\n",
       "      <td>1.123091e-06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp       uid  campaign  conversion  conversion_timestamp  \\\n",
       "0          0  20073966  22589171           0                    -1   \n",
       "1          2  24607497    884761           0                    -1   \n",
       "2          2  28474333  18975823           0                    -1   \n",
       "3          3   7306395  29427842           1               1449193   \n",
       "4          3  25357769  13365547           0                    -1   \n",
       "\n",
       "   conversion_id  attribution  click  click_pos  click_nb  ...      cat4  \\\n",
       "0             -1            0      0         -1        -1  ...  29196072   \n",
       "1             -1            0      0         -1        -1  ...  29196072   \n",
       "2             -1            0      0         -1        -1  ...  29196072   \n",
       "3        3063962            0      1          0         7  ...  23549932   \n",
       "4             -1            0      0         -1        -1  ...  29196072   \n",
       "\n",
       "       cat5      cat6      cat7      cat8      cat9  day              jid  \\\n",
       "0  11409686   1973606  25162884  29196072  29196072    0      20073966_-1   \n",
       "1  11409686   1973606  22644417   9312274  21091111    0      24607497_-1   \n",
       "2   5824237    138937   1795451  29196072  15351056    0      28474333_-1   \n",
       "3   5824237   1973606   9180723  29841067  29196072    0  7306395_3063962   \n",
       "4  11409684  26597096   4480345  29196072  29196072    0      25357769_-1   \n",
       "\n",
       "   timestamp_norm  time_since_last_click_norm  \n",
       "0    0.000000e+00                    0.000000  \n",
       "1    7.487274e-07                    0.163526  \n",
       "2    7.487274e-07                    0.003426  \n",
       "3    1.123091e-06                    0.000000  \n",
       "4    1.123091e-06                    0.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Criteo_Attribution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def sample_campaigns(df, n_campaigns):    \n",
    "    campaigns = np.random.choice( df['campaign'].unique(), n_campaigns, replace = False )\n",
    "    return df[ df['campaign'].isin(campaigns) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Criteo_Attribution = sample_campaigns(df_Criteo_Attribution, n_campaigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9889488, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Criteo_Attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_journeys_by_length(df, min_touchpoints):\n",
    "    if min_touchpoints <= 1:\n",
    "        return df\n",
    "    else:\n",
    "        grouped = df.groupby(['jid'])['uid'].count().reset_index(name=\"count\")\n",
    "        return df[df['jid'].isin( grouped[grouped['count'] >= min_touchpoints]['jid'].values )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Criteo_Attribution = filter_journeys_by_length(df_Criteo_Attribution, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7405691, 26)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Criteo_Attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_conversions(df):\n",
    "    df_minority = df[df.conversion == 1]\n",
    "    df_majority = df[df.conversion == 0]\n",
    "    \n",
    "    df_majority_jids = np.array_split(df_majority['jid'].unique(), 100 * df_majority.shape[0]/df_minority.shape[0] )\n",
    "    \n",
    "    df_majority_sampled = pd.DataFrame(data=None, columns=df.columns)\n",
    "    for jid_chunk in df_majority_jids:\n",
    "        df_majority_sampled = pd.concat([df_majority_sampled, df_majority[df_majority.jid.isin(jid_chunk)]])\n",
    "        if df_majority_sampled.shape[0] > df_minority.shape[0]:\n",
    "            break\n",
    "    \n",
    "    return pd.concat([df_majority_sampled, df_minority]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Criteo_Attribution = balance_conversions(df_Criteo_Attribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579774, 26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Criteo_Attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_one_hot(df, column_names, result_column_name):\n",
    "    mapper = {} \n",
    "    for i, col_name in enumerate(column_names):\n",
    "        for val in df[col_name].unique():\n",
    "            mapper[str(val) + str(i)] = len(mapper)\n",
    "         \n",
    "    df_ext = df.copy()\n",
    "    \n",
    "    def one_hot(values):\n",
    "        v = np.zeros( len(mapper) )\n",
    "        for i, val in enumerate(values): \n",
    "            v[ mapper[str(val) + str(i)] ] = 1\n",
    "        return v    \n",
    "    \n",
    "    df_ext[result_column_name] = df_ext[column_names].values.tolist()\n",
    "    df_ext[result_column_name] = df_ext[result_column_name].map(one_hot)\n",
    "    \n",
    "    return df_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Criteo_Attribution = map_one_hot(df_Criteo_Attribution, ['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat8'], 'cats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Criteo_Attribution.cats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Criteo_Attribution = map_one_hot(df_Criteo_Attribution, ['campaign'], 'campaigns').sort_values(by=['timestamp_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579774, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Criteo_Attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[290278, 289496]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df_Criteo_Attribution[df_Criteo_Attribution.conversion == 0].shape[0], df_Criteo_Attribution[df_Criteo_Attribution.conversion == 1].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>uid</th>\n",
       "      <th>campaign</th>\n",
       "      <th>conversion</th>\n",
       "      <th>conversion_timestamp</th>\n",
       "      <th>conversion_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>click</th>\n",
       "      <th>click_pos</th>\n",
       "      <th>click_nb</th>\n",
       "      <th>...</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>day</th>\n",
       "      <th>jid</th>\n",
       "      <th>timestamp_norm</th>\n",
       "      <th>time_since_last_click_norm</th>\n",
       "      <th>cats</th>\n",
       "      <th>campaigns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65528</th>\n",
       "      <td>2</td>\n",
       "      <td>28474333</td>\n",
       "      <td>18975823</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>138937</td>\n",
       "      <td>1795451</td>\n",
       "      <td>29196072</td>\n",
       "      <td>15351056</td>\n",
       "      <td>0</td>\n",
       "      <td>28474333_-1</td>\n",
       "      <td>7.487274e-07</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387213</th>\n",
       "      <td>3</td>\n",
       "      <td>7306395</td>\n",
       "      <td>29427842</td>\n",
       "      <td>1</td>\n",
       "      <td>1449193</td>\n",
       "      <td>3063962</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1973606</td>\n",
       "      <td>9180723</td>\n",
       "      <td>29841067</td>\n",
       "      <td>29196072</td>\n",
       "      <td>0</td>\n",
       "      <td>7306395_3063962</td>\n",
       "      <td>1.123091e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401488</th>\n",
       "      <td>4</td>\n",
       "      <td>93907</td>\n",
       "      <td>17686799</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1973606</td>\n",
       "      <td>2687461</td>\n",
       "      <td>29841067</td>\n",
       "      <td>21091108</td>\n",
       "      <td>0</td>\n",
       "      <td>93907_-1</td>\n",
       "      <td>1.497455e-06</td>\n",
       "      <td>0.101299</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14394</th>\n",
       "      <td>4</td>\n",
       "      <td>19923387</td>\n",
       "      <td>31772643</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>32440041</td>\n",
       "      <td>14074087</td>\n",
       "      <td>29196072</td>\n",
       "      <td>21091108</td>\n",
       "      <td>0</td>\n",
       "      <td>19923387_-1</td>\n",
       "      <td>1.497455e-06</td>\n",
       "      <td>0.069316</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473426</th>\n",
       "      <td>4</td>\n",
       "      <td>28451570</td>\n",
       "      <td>20843295</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>28928366</td>\n",
       "      <td>8556462</td>\n",
       "      <td>29196072</td>\n",
       "      <td>29196072</td>\n",
       "      <td>0</td>\n",
       "      <td>28451570_-1</td>\n",
       "      <td>1.497455e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp       uid  campaign conversion conversion_timestamp  \\\n",
       "65528          2  28474333  18975823          0                   -1   \n",
       "387213         3   7306395  29427842          1              1449193   \n",
       "401488         4     93907  17686799          0                   -1   \n",
       "14394          4  19923387  31772643          0                   -1   \n",
       "473426         4  28451570  20843295          0                   -1   \n",
       "\n",
       "       conversion_id attribution click click_pos click_nb  ...      cat6  \\\n",
       "65528             -1           0     0        -1       -1  ...    138937   \n",
       "387213       3063962           0     1         0        7  ...   1973606   \n",
       "401488            -1           0     1        -1       -1  ...   1973606   \n",
       "14394             -1           0     0        -1       -1  ...  32440041   \n",
       "473426            -1           0     0        -1       -1  ...  28928366   \n",
       "\n",
       "            cat7      cat8      cat9 day              jid timestamp_norm  \\\n",
       "65528    1795451  29196072  15351056   0      28474333_-1   7.487274e-07   \n",
       "387213   9180723  29841067  29196072   0  7306395_3063962   1.123091e-06   \n",
       "401488   2687461  29841067  21091108   0         93907_-1   1.497455e-06   \n",
       "14394   14074087  29196072  21091108   0      19923387_-1   1.497455e-06   \n",
       "473426   8556462  29196072  29196072   0      28451570_-1   1.497455e-06   \n",
       "\n",
       "       time_since_last_click_norm  \\\n",
       "65528                    0.003426   \n",
       "387213                   0.000000   \n",
       "401488                   0.101299   \n",
       "14394                    0.069316   \n",
       "473426                   0.000000   \n",
       "\n",
       "                                                     cats  \\\n",
       "65528   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "387213  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "401488  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "14394   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "473426  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                campaigns  \n",
       "65528   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "387213  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "401488  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "14394   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "473426  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Criteo_Attribution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets prepare the features for Logistic Regression. We treat this as a Sequence to classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_for_logistic_regression(df):\n",
    "\n",
    "    def pairwise_max(series):\n",
    "        return np.max(series.tolist(), axis = 0).tolist()\n",
    "    \n",
    "    aggregation = {\n",
    "        'campaigns': pairwise_max,\n",
    "        'cats': pairwise_max,\n",
    "        'click': 'sum',\n",
    "        'cost': 'sum',\n",
    "        'conversion': 'max'\n",
    "    }\n",
    "    \n",
    "    df_agg = df.groupby(['jid']).agg(aggregation)\n",
    "    \n",
    "    df_agg['features'] = df_agg[['campaigns', 'cats', 'click', 'cost']].values.tolist()\n",
    "    \n",
    "    return (\n",
    "        np.stack(df_agg['features'].map(lambda x: np.hstack(x)).values),\n",
    "        df_agg['conversion'].values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125836, 1629)\n"
     ]
    }
   ],
   "source": [
    "x, y = features_for_logistic_regression(df_Criteo_Attribution)\n",
    "print(np.shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8756357279084552\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80534 samples, validate on 20134 samples\n",
      "Epoch 1/10\n",
      "80534/80534 [==============================] - 3s 32us/step - loss: 0.5328 - acc: 0.7688 - val_loss: 0.4679 - val_acc: 0.8161\n",
      "Epoch 2/10\n",
      "80534/80534 [==============================] - 2s 28us/step - loss: 0.4519 - acc: 0.8229 - val_loss: 0.4320 - val_acc: 0.8301\n",
      "Epoch 3/10\n",
      "80534/80534 [==============================] - 2s 26us/step - loss: 0.4253 - acc: 0.8350 - val_loss: 0.4123 - val_acc: 0.8402\n",
      "Epoch 4/10\n",
      "80534/80534 [==============================] - 3s 32us/step - loss: 0.4090 - acc: 0.8428 - val_loss: 0.3993 - val_acc: 0.8469\n",
      "Epoch 5/10\n",
      "80534/80534 [==============================] - 2s 29us/step - loss: 0.3975 - acc: 0.8474 - val_loss: 0.3901 - val_acc: 0.8529\n",
      "Epoch 6/10\n",
      "80534/80534 [==============================] - 2s 30us/step - loss: 0.3889 - acc: 0.8519 - val_loss: 0.3827 - val_acc: 0.8548\n",
      "Epoch 7/10\n",
      "80534/80534 [==============================] - 2s 30us/step - loss: 0.3823 - acc: 0.8538 - val_loss: 0.3770 - val_acc: 0.8566\n",
      "Epoch 8/10\n",
      "80534/80534 [==============================] - 2s 28us/step - loss: 0.3767 - acc: 0.8560 - val_loss: 0.3721 - val_acc: 0.8582\n",
      "Epoch 9/10\n",
      "80534/80534 [==============================] - 3s 33us/step - loss: 0.3721 - acc: 0.8578 - val_loss: 0.3680 - val_acc: 0.8593\n",
      "Epoch 10/10\n",
      "80534/80534 [==============================] - 2s 30us/step - loss: 0.3681 - acc: 0.8579 - val_loss: 0.3647 - val_acc: 0.8612\n",
      "Test score: 0.3659233859368971\n",
      "Test accuracy: 0.859504132231405\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.constraints import NonNeg\n",
    "\n",
    "m = np.shape(x)[1]\n",
    "    \n",
    "model = Sequential()  \n",
    "model.add(Dense(1, input_dim=m, activation='sigmoid', name = 'contributions')) \n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_val, y_val)) \n",
    "score = model.evaluate(x_test, y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80534 samples, validate on 20134 samples\n",
      "Epoch 1/20\n",
      "80534/80534 [==============================] - 2s 24us/step - loss: 0.5212 - acc: 0.7909 - val_loss: 0.4649 - val_acc: 0.8210\n",
      "Epoch 2/20\n",
      "80534/80534 [==============================] - 2s 28us/step - loss: 0.4492 - acc: 0.8248 - val_loss: 0.4298 - val_acc: 0.8327\n",
      "Epoch 3/20\n",
      "80534/80534 [==============================] - 2s 24us/step - loss: 0.4234 - acc: 0.8366 - val_loss: 0.4112 - val_acc: 0.8406\n",
      "Epoch 4/20\n",
      "80534/80534 [==============================] - 3s 41us/step - loss: 0.4078 - acc: 0.8437 - val_loss: 0.3985 - val_acc: 0.8482\n",
      "Epoch 5/20\n",
      "80534/80534 [==============================] - 3s 35us/step - loss: 0.3967 - acc: 0.8481 - val_loss: 0.3892 - val_acc: 0.8520\n",
      "Epoch 6/20\n",
      "80534/80534 [==============================] - 3s 32us/step - loss: 0.3881 - acc: 0.8521 - val_loss: 0.3823 - val_acc: 0.8547\n",
      "Epoch 7/20\n",
      "80534/80534 [==============================] - 2s 25us/step - loss: 0.3815 - acc: 0.8537 - val_loss: 0.3765 - val_acc: 0.8571\n",
      "Epoch 8/20\n",
      "80534/80534 [==============================] - 2s 25us/step - loss: 0.3758 - acc: 0.8562 - val_loss: 0.3713 - val_acc: 0.8590\n",
      "Epoch 9/20\n",
      "80534/80534 [==============================] - 2s 26us/step - loss: 0.3710 - acc: 0.8579 - val_loss: 0.3673 - val_acc: 0.8602\n",
      "Epoch 10/20\n",
      "80534/80534 [==============================] - 3s 35us/step - loss: 0.3670 - acc: 0.8598 - val_loss: 0.3637 - val_acc: 0.8618\n",
      "Epoch 11/20\n",
      "80534/80534 [==============================] - 2s 29us/step - loss: 0.3634 - acc: 0.8611 - val_loss: 0.3606 - val_acc: 0.8626\n",
      "Epoch 12/20\n",
      "80534/80534 [==============================] - 2s 30us/step - loss: 0.3602 - acc: 0.8626 - val_loss: 0.3582 - val_acc: 0.8626\n",
      "Epoch 13/20\n",
      "80534/80534 [==============================] - 2s 28us/step - loss: 0.3575 - acc: 0.8627 - val_loss: 0.3552 - val_acc: 0.8638\n",
      "Epoch 14/20\n",
      "80534/80534 [==============================] - 2s 29us/step - loss: 0.3549 - acc: 0.8637 - val_loss: 0.3530 - val_acc: 0.8650\n",
      "Epoch 15/20\n",
      "80534/80534 [==============================] - 2s 28us/step - loss: 0.3526 - acc: 0.8649 - val_loss: 0.3510 - val_acc: 0.8649\n",
      "Epoch 16/20\n",
      "80534/80534 [==============================] - 2s 28us/step - loss: 0.3505 - acc: 0.8654 - val_loss: 0.3492 - val_acc: 0.8664\n",
      "Epoch 17/20\n",
      "80534/80534 [==============================] - 3s 34us/step - loss: 0.3485 - acc: 0.8657 - val_loss: 0.3473 - val_acc: 0.8670\n",
      "Epoch 18/20\n",
      "80534/80534 [==============================] - 2s 28us/step - loss: 0.3467 - acc: 0.8668 - val_loss: 0.3459 - val_acc: 0.8672\n",
      "Epoch 19/20\n",
      "80534/80534 [==============================] - 2s 27us/step - loss: 0.3450 - acc: 0.8679 - val_loss: 0.3442 - val_acc: 0.8676\n",
      "Epoch 20/20\n",
      "80534/80534 [==============================] - 2s 27us/step - loss: 0.3434 - acc: 0.8675 - val_loss: 0.3428 - val_acc: 0.8677\n",
      "Test score: 0.3446481671783474\n",
      "Test accuracy: 0.8664176732358551\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.constraints import NonNeg\n",
    "\n",
    "m = np.shape(x)[1]\n",
    "    \n",
    "model1 = Sequential()  \n",
    "model1.add(Dense(1, input_dim=m, activation='sigmoid', name = 'contributions')) \n",
    "\n",
    "model1.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "history = model1.fit(x_train, y_train, batch_size=64, epochs=20, verbose=1, validation_data=(x_val, y_val)) \n",
    "score = model1.evaluate(x_test, y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAENCAYAAACmZfCPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X1clHW+//H3zAASoMDMhCxGmSiPjlp5Q4m0eQdnt9TdNR5rbp1M0+3OxIjOOeuxs6fT2WPHbrwJMe1mQn3k6VD7WFu3ba1Y1tokH2GKm90pq92QJMKAoUgKM78/fDS/pgv0UriYAV7Pv7i+1/e6rs81c80115vrZmx+v98vAAAAAAC+wx7qAgAAAAAA4YewCAAAAAAwICwCAAAAAAwIiwAAAAAAA8IiAAAAAMCAsAgAAAAAMCAsAgAAAAAMCIsAAAAAAAPCIgAAAADAgLAIAAAAADCICHUBoXDo0KFQl3BGbrdbdXV1oS4DvRTbF6zGNgYrsX3BamxjsFK4bF8pKSmm+nFmEQAAAABgQFgEAAAAABgQFgEAAAAABoRFAAAAAIABYREAAAAAYEBYBAAAAAAYEBYBAAAAAAaERQAAAACAAWERAAAAAGAQEeoCAACwStvtP2233fHMlm6uBACAnocziwAAAAAAA8IiAAAAAMCAsAgAAAAAMCAsAgAAAAAMCIsAAAAAAAPCIgAAAADAgLAIAAAAADAgLAIAAAAADAiLAAAAAAADwiIAAAAAwICwCAAAAAAwICwCAAAAAAwIiwAAAAAAA8IiAAAAAMCAsAgAAAAAMCAsAgAAAAAMCIsAAAAAAAPCIgAAAADAgLAIAAAAADCI6K4FVVZWqri4WD6fT9nZ2ZoxY0bQ+FOnTqmoqEgHDhxQ//79lZ+fr6SkJEnS5s2bVVZWJrvdrttuu02jRo0KTOfz+bR48WI5nU4tXry4u1YHAAAAAHq1bjmz6PP55PF4tGTJEq1cuVLbt29XdXV1UJ+ysjLFxsZq9erVmjZtmjZt2iRJqq6uVnl5uVasWKEHHnhAHo9HPp8vMN2rr76qQYMGdcdqAAAAAECf0S1hsaqqSsnJyRo4cKAiIiKUlZWlioqKoD47d+7UpEmTJEmZmZnau3ev/H6/KioqlJWVpcjISCUlJSk5OVlVVVWSpPr6eu3atUvZ2dndsRoAAAAA0Gd0S1j0er1yuVyBYZfLJa/X22Efh8OhmJgYNTU1GaZ1Op2BadevX69bbrlFNputG9YCAAAAAPqObrln0e/3G9q+H/A66tNeuyS99957io+P15AhQ/TBBx+ccfmlpaUqLS2VJC1btkxut9ts6SERERER9jWi52L7gtXCaRs73EF7uNSHcxdO2xd6J7YxWKmnbV/dEhZdLpfq6+sDw/X19UpMTGy3j8vlUltbm5qbmxUXF2eY1uv1yul0aufOndq5c6d2796tkydP6sSJEyosLNSiRYsMy8/JyVFOTk5guK6uzoK17Dputzvsa0TPxfYFq/WEbSzc60PHesL2hZ6NbQxWCpftKyUlxVS/bgmLaWlpqqmpUW1trZxOp8rLyw2hbuzYsdq2bZvS09O1Y8cOjRgxQjabTRkZGSosLNT06dPV0NCgmpoaDR06VOnp6br55pslSR988IH+8Ic/tBsUAQAAQqHt9p+22+54Zks3VwIA56dbwqLD4dC8efO0dOlS+Xw+TZ48WampqSopKVFaWpoyMjI0ZcoUFRUVKS8vT3FxccrPz5ckpaamavz48SooKJDdbtf8+fNlt/PzkAAAAABgJZu/o5sCe7FDhw6FuoQzCpfT0+id2L5gtXDaxjiz0/uE0/Z1Nmx/PVNP2sbQ84TL9mX2MlRO0QEAAAAADAiLAAAAAAADwiIAAAAAwICwCAAAAAAwMP001D179ujTTz9VS0tLUPusWbO6vCgAAAAAQGiZCosej0fvvPOORowYoX79+lldEwBYjqcUAgAAnJmpsLh9+3Y9+uijcrvdVtcDAOhARwFXIuQCAICuZ+qexf79+ys2NtbqWgAAAAAAYcLUmcXp06ersLBQN9xwg+Lj44PGDRw40JLCAAAAAAChYyosPvvss5KkXbt2GcaVlJR0bUUAAAAAgJAzFRYJhAAAAADQt5j+6QxJqqurk9frldPp5GE3AAAAANCLmQqLDQ0NWrVqlfbt26f+/furqalJ6enpuvfee+V0Oq2uEegT+CkHAAAAhBNTT0N95plndMkll6i4uFhPP/20iouLNXjwYD3zzDNW1wcAAAAACAFTYfGTTz7RrbfequjoaElSdHS0brnlFu3bt8/S4gAAAAAAoWEqLMbGxqq6ujqo7dChQ4qJibGkKAAAAABAaJm6Z/GnP/2pfvOb32jKlCm68MILdeTIEW3btk2zZs2yuj4AAAAAQAiYCos5OTlKTk7W22+/rc8//1yJiYm69957NXLkSKvrAwAAAACEgOmfzhg5ciThEAAAAAD6iA7D4u9+9zvl5uZKkkpKSjqcAZeiAgAAAEDv02FYrK+vb/dvAAAAAEDv12FYvP322wN/L1iwoFuKAQAAAACEB1P3LFZXVysuLk4JCQlqaWnRli1bZLfb9ZOf/ET9+vWzukYAAAAAQDczFRafeOIJ3XfffUpISNDGjRtVU1OjyMhIPf3008rLy7O6RnRC2+0/7XCc45kt3VhJz9HRa8brBQAAgL7EVFg8cuSIUlJS5Pf7VVFRoeXLlysqKkoLFy60uj4AAAAAQAiYCouRkZE6ceKEqqur5XK5NGDAALW1tenUqVNW1wcAAPq4717xcfg77VzxAQDWMhUWr7nmGv3Xf/2XTpw4oeuuu06SdPDgQSUlJVlaHAAAAAAgNEyFxblz52rPnj1yOBwaOXKkJMlms2nOnDmWFgcAAAAACA1TYVGSrrzyysDfhw8f1oABA5SWlmZJUQAAAACA0LKb6bRq1Sp98sknkqS//OUvKigoUEFBgcrKyiwtDgAAAAAQGqbC4t69ewNnEV955RX9+te/1sMPP6yXX37Z0uIAAAAAAKFh6jLU1tZWRUREyOv16tixY7rsssskSUePHrW0OAAAAAC9B79n3bOYCouDBw/W5s2bdeTIEY0ZM0aS5PV6dcEFF1haHAAAfU1HB1ISB1Mwh4NxAF3FVFi86667VFJSIofDodmzZ0uS9u3bpx/+8IeWFofT2OkDAHo6vsvQU51t22XbRm9mKiwmJyfr3nvvDWrLzMxUZmamJUUBACBxlg0AgFAyFRb9fr/+/Oc/q7y8XF9//bUef/xxffjhh2psbFRWVpbVNQIAQoz/nANA78J+HWaYCoslJSV6//33NXXqVD3zzDOSJJfLpQ0bNhAWAQAAuhgH8gDCgamw+Oabb+qRRx7RgAED9Oyzz0qSkpKSVFtba3pBlZWVKi4uls/nU3Z2tmbMmBE0/tSpUyoqKtKBAwfUv39/5efnKykpSZK0efNmlZWVyW6367bbbtOoUaN08uRJPfjgg2ptbVVbW5syMzN14403mq4HAAAAANAxU7+z6PP5FB0dHdTW0tJiaDvT9B6PR0uWLNHKlSu1fft2VVdXB/UpKytTbGysVq9erWnTpmnTpk2SpOrqapWXl2vFihV64IEH5PF45PP5FBkZqQcffFCPPfaYHn30UVVWVmrfvn2m6gEAAAAAnJmpM4ujRo3Sxo0bNWfOHEmn72EsKSnR2LFjTS2kqqpKycnJGjhwoCQpKytLFRUVuuiiiwJ9du7cqZkzZ0o6/fCc5557Tn6/XxUVFcrKylJkZKSSkpKUnJysqqoqpaenB8JqW1ub2traZLPZzK85ejQuzwHCy3c/k4e/096TP5PsZwAAfZ2psDhnzhwVFRVp7ty5am1t1a233qorrrhCCxcuNLUQr9crl8sVGHa5XNq/f3+HfRwOh2JiYtTU1CSv16thw4YF+jmdTnm9Xkmnz1j+6le/0ldffaUf//jHQf2+q7S0VKWlpZKkZcuWye12m6o7VCIiIoJqPNxBPzPr0dG0Zqe30uEb2r/fdeDm8rNP20F7V6yTlfMOh+V+f/vqq0L1PndGKD/PZ3u9rHo9O7vOVuw/Q/Vad8eyrdQT34vOCtU699TXK1yc63FYT329w20fF+6vV1fpacdhZw2Lfr9fTU1Nuv/++3Xs2DEdOXJEbrdbCQkJphfi9/sNbd8/C9hRn/bav2W32/XYY4/p+PHjevzxx/X555/r4osvNvTLyclRTk5OYLiurs507aHgdrtN1djZ9QjX16EzdVm5TqF6vbp6uWa3r76qp7424bp9hutnMlz3M+G8bKv01PeiM/rittuTdNVxWE99vcP1+6S3CJfjsJSUFFP9znrPos1m0z//8z/LZrMpPj5eQ4cOPaegKJ0+k1hfXx8Yrq+vV2JiYod92tra1NzcrLi4OMO0Xq9XTqczaNrY2FgNHz5clZWV51QXAAAAAKB9pi5DHTx4sGpqajRo0KDzWkhaWppqampUW1srp9Op8vJyLVq0KKjP2LFjtW3bNqWnp2vHjh0aMWKEbDabMjIyVFhYqOnTp6uhoUE1NTUaOnSovv76azkcDsXGxurkyZN6//339bOf/ey86gOArsS9bgCAvqqj70CJ78GeyFRYHDFihB5++GFNnDjRcI3tlClTzjq9w+HQvHnztHTpUvl8Pk2ePFmpqakqKSlRWlqaMjIyNGXKFBUVFSkvL09xcXHKz8+XJKWmpmr8+PEqKCiQ3W7X/PnzZbfb1dDQoDVr1sjn88nv92v8+PGmH7gDAAAAADgzU2Hxk08+UVJSkj766CPDODNhUZLGjBmjMWPGBLXNmjUr8HdUVJQKCgranTY3N1e5ublBbZdccokeffRRU8sGAAAAYA5XyOBbpsLigw8+aHUd6AQ+0AAAAMCZccx87kyFRUk6fvy4du3apYaGBiUmJmrMmDGKjY21sjYA6HX4ogIAAD3FWZ+GKkl79+7VPffcoz/96U+qqqrS1q1bdc899+j999+3uj4AAAAAQAiYOrPo8Xh0xx13KCvr//+I+jvvvCOPx6NVq1ZZVhyA0ONMGAB0PZ4YCXQ9jlm6nqmw2NDQoMzMzKC2q6++Wk899ZQlRQEAAISD3njw2RvXCYA1TIXFCRMmaOvWrZo6dWqg7fXXX9eECRMsKwwAcG44AAQAAF3JVFg8ePCg3njjDW3ZskVOp1Ner1dHjx7VsGHDgp6U+tBDD1lWKAAAAACg+5gKi9nZ2crOzra6FgAAgB6Ds/kAejtTYXHSpEkWlwEglDjgAQCYwfcF0LeY/p3Fjz76SAcPHlRLS0tQe25ubpcXBQAAAHQVQm7X4vXsO0yFxeeee07vvPOOLrvsMkVFRQXabTabZYUBAIBzx0EcAKCrmAqLf/3rX7V8+XI5nU6r6wEAAAAAhAG7mU5ut1uRkZFW1wIAAAAACBOmzizeddddeuqpp3TNNdcoPj4+aNzw4cMtKQwAAKCzuCwXAM6fqbB44MAB7d69Wx999FHQPYuStHbtWksKAxCMAx4AAAB0J1Nh8YUXXtCvfvUrXXHFFVbXAwAAcE74ZxrCVUfbpsT2iZ7B1D2L/fr143JTAAAAAOhDTJ1ZnDVrltavX6+f//znGjBgQNA4u91U3gQAAADC0nfPAB7+Tjtn/9DXmQqL396X+MYbbxjGlZSUdG1FALqclV+CXP4FAADQO5kKi0VFRVbXAQAAAJP4Rx2A7mAqLF544YVW1wEA6KU4qAWA9rF/RLjrMCw+9dRTuvPOOyVJq1evls1ma7ffwoULrakMAAAAABAyHYbFpKSkwN/JycndUgwAAAAAIDx0GBZvuOGGwN8zZ87slmL6Mp7Chb6oM5ff8NtVAAAA1jJ1zyLQm3B/AAAAALpKb/4HNmER6EIEUQAS+4KehPcKADpGWAQA9Fgc6PcOvfm/8gB6h776fXPWsOjz+fTSSy8pNzdXkZGR3VETeom++qECAADdi2MOwBpnDYt2u12vvfYaD7kB0Gdw0AEAQN/Cd3/7TF2GOnHiRL3xxhv68Y9/bHU9AAD0CBxYAAB6O1NhsaqqSlu3btWWLVvkcrlks9kC4x566CHLikPfxUEYAAAAEFqmwmJ2drays7OtrgUAAIQQ/6gDeg4+r+gOpsLipEmTLC4DANBXccADAEB4MhUW/X6//vznP2v79u1qamrS448/rg8//FCNjY3KysqyukYAgMUIbAAA4PvsZjqVlJToL3/5i3JyclRXVydJcrlc+v3vf29pcQAAAACA0DB1ZvHNN9/UI488ogEDBujZZ5+VJCUlJam2ttbS4mA9ziYAAAD0PhzjoSuYOrPo8/kUHR0d1NbS0mJoAwAAAAD0DqbOLI4ePVobN27UnDlzJJ2+h7GkpERjx441vaDKykoVFxfL5/MpOztbM2bMCBp/6tQpFRUV6cCBA+rfv7/y8/OVlJQkSdq8ebPKyspkt9t12223adSoUaqrq9OaNWvU2Ngom82mnJwcTZ061XQ9AAAAAICOmTqzeOutt8rr9Wru3Llqbm7WrbfeqiNHjuif/umfTC3E5/PJ4/FoyZIlWrlypbZv367q6uqgPmVlZYqNjdXq1as1bdo0bdq0SZJUXV2t8vJyrVixQg888IA8Ho98Pp8cDodmz56tlStXaunSpXrttdcM8wQAAAAAnB9TZxZjYmL0r//6rzp69KiOHDkit9uthIQE0wupqqpScnKyBg4cKEnKyspSRUWFLrrookCfnTt3aubMmZKkzMxMPffcc/L7/aqoqFBWVpYiIyOVlJSk5ORkVVVVKT09XYmJiZKkCy64QIMGDZLX6w2aJwAAAADg/JgKi5J0/Phx/e1vf1NDQ4MSExM1evRoxcXFmZrW6/XK5XIFhl0ul/bv399hH4fDoZiYGDU1Ncnr9WrYsGGBfk6nU16vN2ja2tpaHTx4UEOHDm13+aWlpSotLZUkLVu2TG6321Td3elwB+1ut/uM4853WrPz7gwr6jYzrZV1dXbe4VpXuL4X5zNtVyy7s58Lq+Zt5ee5s+9zuO7DwvVzcz7L7ez0Vk/bmXlb+T73xW07XPfbVuqt7/OZ9MV1PptwXefvioiICPnn5VyYCot79+7V448/rpSUFLndbtXX18vj8ej+++/X5Zdfftbp/X6/oc1ms5nq0177d7W0tGj58uWaO3euYmJi2u2Tk5OjnJycwPC3P//RE5yp1rOtR2fGW/kaWVlXZ+oO5bw7M22o5h2ur5eVy7ayrnCddyj3Mz11+wzV+xyu03Z23la9z+G8/YXrOls1rZXC9b3o7LytWu7ZxofrOp9NOK2z2+0Oi89LSkqKqX6mwqLH49Edd9yhrKysQNs777wjj8ejVatWnXV6l8ul+vr6wHB9fX3gEtLv93G5XGpra1Nzc7Pi4uIM03q9XjmdTklSa2urli9frmuvvVbjxo0zsyoAAAAAABNMhcWGhgZlZmYGtV199dV66qmnTC0kLS1NNTU1qq2tldPpVHl5uRYtWhTUZ+zYsdq2bZvS09O1Y8cOjRgxQjabTRkZGSosLNT06dPV0NCgmpoaDR06VH6/X+vWrdOgQYM0ffp0k6uLc8Vv9AAAgK7Q0TGFxHEFEK5MhcUJEyZo69atQT9N8frrr2vChAmmFuJwODRv3jwtXbpUPp9PkydPVmpqqkpKSpSWlqaMjAxNmTJFRUVFysvLU1xcnPLz8yVJqampGj9+vAoKCmS32zV//nzZ7XZ9/PHHeuutt3TxxRfrX/7lXyRJN910k8aMGXOurwEAAAAA4HtMhcWDBw/qjTfe0JYtWwIPmDl69KiGDRumBx98MNDvoYce6nAeY8aMMQS5WbNmBf6OiopSQUFBu9Pm5uYqNzc3qO2yyy7Tiy++aKZ8AAAAAMA5MhUWs7OzlZ2dbXUtQK/HZb0AAMAsjhsQaqbC4qRJkywuAwAAAAAQTkz/ziIAAOganC0AAPQE9lAXAAAAAAAIP4RFAAAAAIABYREAAAAAYGDqnsXW1lZt27ZNn376qVpaWoLGLVy40JLCAPQO3JsFAADQM5kKi0VFRfrss880duxYxcfHW10TAAAAACDETIXFPXv2qKioSLGxsVbXAwAAAAAIA6buWXS73Tp16pTVtQAAAAAAwoSpM4sTJkzQY489puuvv14JCQlB40aOHGlJYQh/3IsGAAAA9F6mwuLWrVslSS+88EJQu81mU1FRUddXBQAAAAAIKVNhcfXq1bLb+ZUNAAB6Mq4IAQCci7OGRZ/Pp9mzZ2v9+vWKjIzsjpoAAADQx/DPDCD8nDUs2u12paSkqKmpSU6nsztqAoCwxgENAHQ/9r1A9zN1GeoPf/hDPfLII7r++uvlcrlks9kC43jADYBwxEEF0PX4XAFA32IqLL7++uuSpJdeeimonQfcAAAAAEDvZCosrlmzxuo6AAAAAABhhEecAgAAAAAMTJ1ZvPvuuzsct3bt2i4rBugKHd1TI3FfDQAAAGCWqbCYl5cXNNzQ0KBXX31V11xzjSVFAQAAAABCy1RYHD58uKFtxIgRWrp0qaZOndrlRQEAgJ6FJ6UCQO9jKiy2O2FEhGpra7uyFgAAAIQYwR/At0yFxZKSkqDhb775Rrt379bo0aMtKQoAALSPA3kAQHcxFRbr6+uDhvv166fp06drwoQJlhQFAAAAAAgtU2Hx5ptvVkJCgqG9sbGx3XYAAMIdZ+gAADgzU2Hx3nvv1YYNGwzt9913n4qLi7u8KCBccXAJAAAQGhyHdT9TYdHv9xvampubZbfbu7wgAOjL+CIEAADh4oxh8e6775YknTx5MvD3t44dO8bvLAIAAABAL3XGsJiXlye/36//+Z//UV5eXtC4hIQEpaSkWFocgL6Ns2wAAPQtfPeHlzOGxeHDh0uSPB6P+vXr1y0FAQAAAABCz9Q9i3a7XS+88IK2b9+upqYmbdiwQXv27FFNTY2uu+46q2sEAAAAAHQzU0+oWb9+vb744gstWrRINptNkpSamqrXX3/d0uIAAAAAAKFh6sxiRUWFCgsLFR0dHQiLTqdTXq/X0uIAAF2H+0AAAMC5MHVmMSIiQj6fL6jt66+/Vv/+/S0pCgAAAAAQWqbCYmZmpoqKilRbWytJamhokMfjUVZWlqXFAQAAAABCw9RlqDfffLOef/553X///Tp58qQWLVqk7Oxs/fznPze9oMrKShUXF8vn8yk7O1szZswIGn/q1CkVFRXpwIED6t+/v/Lz85WUlCRJ2rx5s8rKymS323Xbbbdp1KhRkqQnn3xSu3btUnx8vJYvX266FgAAAHQ9LncHehdTYTEiIkJz587V3LlzA5effnvvohk+n08ej0f//u//LpfLpX/7t39TRkaGLrrookCfsrIyxcbGavXq1dq+fbs2bdqk++67T9XV1SovL9eKFSvU0NCg3/zmN3riiSdkt9s1adIkXXfddVqzZs25rzkAAAAAoEOmLkP9rgEDBshms+mzzz7TihUrTE1TVVWl5ORkDRw4UBEREcrKylJFRUVQn507d2rSpEmSTl/2unfvXvn9flVUVCgrK0uRkZFKSkpScnKyqqqqJJ3+Hci4uLhzXQUAAAAAwFmc8cziN998o82bN+vTTz/VD37wA82cOVNNTU3auHGj/va3v2nixImmFuL1euVyuQLDLpdL+/fv77CPw+FQTEyMmpqa5PV6NWzYsEA/nsIKAAAAANY7Y1j0eDw6ePCgrrzySlVWVurzzz/XoUOHNHHiRN15550aMGCAqYX4/X5D2/cvY+2oT3vt56q0tFSlpaWSpGXLlsntdnd6nl3tcAftbrf7jOPOd1or521mWivn3RfX+Wx64zr3xfeZde6eebPO3T9v1rl75s06d/+8WefumXe4r/N3RUREhGUW6cgZw+KePXv06KOPKj4+Xtdff70WLFig//zP/9Q//MM/nNNCXC6X6uvrA8P19fVKTExst4/L5VJbW5uam5sVFxdnmNbr9crpdJ7T8nNycpSTkxMYrqurO6fpQ+lMtZ5tPTozPlTT9tR5h7qujh4oIJ35oQI9eZ1DMe9wrcvKeYdrXVbOO1zrsnLe4VqXlfMO17qsnHe41mXlvMO1LivnHa51WTnvcK2rvfFutzssskhKSoqpfme8Z7GlpUXx8fGSToe56Ojocw6KkpSWlqaamhrV1taqtbVV5eXlysjICOozduxYbdu2TZK0Y8cOjRgxQjabTRkZGSovL9epU6dUW1urmpoaDR069JxrAAAAAACYd8Yzi21tbdq7d29Q2/eHR44cedaFOBwOzZs3T0uXLpXP59PkyZOVmpqqkpISpaWlKSMjQ1OmTFFRUZHy8vIUFxen/Px8SVJqaqrGjx+vgoIC2e12zZ8/X3b76Yy7atUqffjhh2pqatJdd92lG2+8UVOmTDmnFwAAAAAAYHTGsBgfH6+1a9cGhuPi4oKGbTabioqKTC1ozJgxGjNmTFDbrFmzAn9HRUWpoKCg3Wlzc3OVm5traP82UAIAAAAAutYZwyK/XwgAAAAAfdM5/84iAAAAAKD3IywCAAAAAAwIiwAAAAAAA8IiAAAAAMCAsAgAAAAAMCAsAgAAAAAMCIsAAAAAAAPCIgAAAADAgLAIAAAAADAgLAIAAAAADAiLAAAAAAADwiIAAAAAwICwCAAAAAAwICwCAAAAAAwIiwAAAAAAA8IiAAAAAMCAsAgAAAAAMCAsAgAAAAAMCIsAAAAAAAPCIgAAAADAgLAIAAAAADAgLAIAAAAADAiLAAAAAAADwiIAAAAAwICwCAAAAAAwICwCAAAAAAwIiwAAAAAAA8IiAAAAAMCAsAgAAAAAMCAsAgAAAAAMCIsAAAAAAAPCIgAAAADAgLAIAAAAADAgLAIAAAAADAiLAAAAAAADwiIAAAAAwCCiuxZUWVmp4uJi+Xw+ZWdna8aMGUHjT506paKiIh04cED9+/dXfn6+kpKSJEmbN29WWVmZ7Ha7brvtNo0aNcrUPAEAAAAA56dbziz6fD55PB4tWbJEK1eu1Pbt21VdXR3Up6ysTLGxsVq9erWmTZumTZs2SZKqq6tVXl6uFStW6IEHHpDH45HP5zM1TwAAAADA+emWsFhVVaXk5GQNHDhQERERysoKWcWLAAANNElEQVTKUkVFRVCfnTt3atKkSZKkzMxM7d27V36/XxUVFcrKylJkZKSSkpKUnJysqqoqU/MEAAAAAJyfbgmLXq9XLpcrMOxyueT1ejvs43A4FBMTo6amJsO0TqdTXq/X1DwBAAAAAOfH5vf7/VYv5J133tGePXt01113SZLeeustVVVVad68eYE+BQUFeuCBBwIBMC8vTw8//LBKSkqUnp6uCRMmSJLWrl2r0aNHy+/3n3We3yotLVVpaakkadmyZZauKwAAAAD0Bt1yZtHlcqm+vj4wXF9fr8TExA77tLW1qbm5WXFxcYZpvV6vnE6nqXl+KycnR8uWLesxQXHx4sWhLgG9GNsXrMY2BiuxfcFqbGOwUk/bvrolLKalpammpka1tbVqbW1VeXm5MjIygvqMHTtW27ZtkyTt2LFDI0aMkM1mU0ZGhsrLy3Xq1CnV1taqpqZGQ4cONTVPAAAAAMD56ZafznA4HJo3b56WLl0qn8+nyZMnKzU1VSUlJUpLS1NGRoamTJmioqIi5eXlKS4uTvn5+ZKk1NRUjR8/XgUFBbLb7Zo/f77s9tMZt715AgAAAAA6r1vuWcS5KS0tVU5OTqjLQC/F9gWrsY3BSmxfsBrbGKzU07YvwiIAAAAAwKBb7lkEAAAAAPQs3XLPIsyprKxUcXGxfD6fsrOzNWPGjFCXhB6urq5Oa9asUWNjo2w2m3JycjR16lQdO3ZMK1eu1JEjR3ThhRfqvvvuU1xcXKjLRQ/l8/m0ePFiOZ1OLV68WLW1tVq1apWOHTumSy+9VHl5eYqI4OsG5+f48eNat26dvvjiC9lsNt19991KSUlhH4Yu8corr6isrEw2m02pqalasGCBGhsb2YfhvD355JPatWuX4uPjtXz5cknq8LjL7/eruLhYu3fvVr9+/bRgwQINGTIkxGsQjDOLYcLn88nj8WjJkiVauXKltm/frurq6lCXhR7O4XBo9uzZWrlypZYuXarXXntN1dXVevnll3X55ZersLBQl19+uV5++eVQl4oe7NVXX9WgQYMCw88//7ymTZumwsJCxcbGqqysLITVoacrLi7WqFGjtGrVKj322GMaNGgQ+zB0Ca/Xqz/96U9atmyZli9fLp/Pp/LycvZh6JRJkyZpyZIlQW0d7bN2796tr776SoWFhbrjjjv07LPPhqLkMyIshomqqiolJydr4MCBioiIUFZWlioqKkJdFnq4xMTEwH+oLrjgAg0aNEher1cVFRWaOHGiJGnixIlsazhv9fX12rVrl7KzsyVJfr9fH3zwgTIzMyWd/tJk+8L5am5u1kcffaQpU6ZIkiIiIhQbG8s+DF3G5/Pp5MmTamtr08mTJ5WQkMA+DJ0yfPhww5UOHe2zdu7cqQkTJshmsyk9PV3Hjx9XQ0NDt9d8JpxTDxNer1culysw7HK5tH///hBWhN6mtrZWBw8e1NChQ3X06FElJiZKOh0ov/766xBXh55q/fr1uuWWW3TixAlJUlNTk2JiYuRwOCRJTqdTXq83lCWiB6utrdWAAQP05JNP6rPPPtOQIUM0d+5c9mHoEk6nUz/5yU909913KyoqSldeeaWGDBnCPgxdrqN9ltfrldvtDvRzuVzyer2BvuGAM4thor2H0tpsthBUgt6opaVFy5cv19y5cxUTExPqctBLvPfee4qPjw+7+yvQe7S1tengwYP60Y9+pEcffVT9+vXjklN0mWPHjqmiokJr1qzRU089pZaWFlVWVoa6LPQhPeH4nzOLYcLlcqm+vj4wXF9fH1b/VUDP1draquXLl+vaa6/VuHHjJEnx8fFqaGhQYmKiGhoaNGDAgBBXiZ7ok08+0c6dO7V7926dPHlSJ06c0Pr169Xc3Ky2tjY5HA55vV45nc5Ql4oeyuVyyeVyadiwYZKkzMxMvfzyy+zD0CXef/99JSUlBbafcePG6ZNPPmEfhi7X0T7L5XKprq4u0C8cj/85sxgm0tLSVFNTo9raWrW2tqq8vFwZGRmhLgs9nN/v17p16zRo0CBNnz490J6RkaE333xTkvTmm2/qqquuClWJ6MFuvvlmrVu3TmvWrFF+fr5GjhypRYsWacSIEdqxY4ckadu2bezLcN4SEhLkcrl06NAhSacP7i+66CL2YegSbrdb+/fv1zfffCO/3x/YvtiHoat1tM/KyMjQW2+9Jb/fr3379ikmJibswqLN3975T4TErl27tGHDBvl8Pk2ePFm5ubmhLgk93Mcff6z/+I//0MUXXxy4rOGmm27SsGHDtHLlStXV1cntdqugoIDHzqNTPvjgA/3hD3/Q4sWLdfjwYcNj5yMjI0NdInqoTz/9VOvWrVNra6uSkpK0YMEC+f1+9mHoEi+++KLKy8vlcDg0ePBg3XXXXfJ6vezDcN5WrVqlDz/8UE1NTYqPj9eNN96oq666qt19lt/vl8fj0Z49exQVFaUFCxYoLS0t1KsQhLAIAAAAADDgMlQAAAAAgAFhEQAAAABgQFgEAAAAABgQFgEAAAAABoRFAAAAAIABYREAgBCqq6vT7Nmz5fP5Ql0KAABB+OkMAECv9fbbb+uVV17Rl19+qQsuuECDBw9Wbm6uLrvsslCX1i3WrFkjl8ulX/ziF6qtrdXChQvVr18/SVJ0dLTS0tI0depUXXHFFSGuFAAQjiJCXQAAAFZ45ZVX9PLLL+v222/XlVdeqYiICFVWVqqioqLPhMX2rF+/Xg6HQ42NjSovL9djjz2m+fPna9KkSaEuDQAQZgiLAIBep7m5WSUlJVqwYIHGjRsXaM/IyFBGRoYkqaqqSsXFxfryyy8VFRWlcePGac6cOYqIOP3VeOONN2r+/Pn64x//qMbGRk2dOlWTJk3S6tWrVV1drSuvvFKLFi1SRESEPvjgA61evVo/+tGP9Mc//lHR0dH6xS9+oWuvvVaStGvXLv3f//2fDh8+rJiYGE2ePFk33nijJAXO+L3wwgtyOByqra3VmjVrdPDgQQ0bNkw/+MEP1NzcrEWLFgX6LliwQCUlJTp58qSmTZum3Nzcc36NEhISNHXqVLW2tmrTpk2aMGGC7HbuTgEA/H98KwAAep19+/bp1KlTuvrqqzvsY7fbNWfOHHk8Hv33f/+39u7dq9deey2oT2VlpZYtW6alS5dqy5Ytevrpp7Vo0SKtXbtWX3zxhd5+++1A38bGRjU1NWndunW655579PTTT+vQoUOSpH79+mnhwoUqLi7W4sWL9cYbb+jdd99tt64nnnhCaWlpeu655zRz5kz99a9/NfT5+OOP9cQTT+jXv/61fvvb36q6uvp8XiZJ0rhx43T06NFArQAAfIuwCADodZqamtS/f385HI4O+wwZMkTp6elyOBxKSkpSTk6OPvzww6A+P/vZzxQTE6PU1FSlpqbqiiuu0MCBAxUTE6PRo0fr008/Deo/a9YsRUZGavjw4Ro9erTKy8slSSNGjNDFF18su92uSy65RNdcc41hWdLph938/e9/16xZsxQREaHLLrtMY8eONfSbOXOmoqKiNHjwYF1yySX67LPPzuNVOi0xMVGSdOzYsfOeBwCgd+IyVABAr9O/f381NTWpra2tw8B46NAhbdy4UX//+9918uRJtbW1aciQIUF9EhISAn9HRUUZhhsbGwPDsbGxio6ODgxfeOGFamhokCTt379f//u//6vPP/9cra2tam1tVWZmpqEmr9eruLi4wENoJMntdquurq7Duvr166eWlpYzvh5n4vV6JUlxcXHnPQ8AQO/EmUUAQK+Tnp6uyMhIVVRUdNjn2WefVUpKigoLC7VhwwbddNNN6swDwo8fPx4U2urq6gJn7QoLCzV27FitXbtWGzZs0D/+4z+2u6zExEQdO3ZM33zzTdB8rPTuu+8qPj5eKSkpli4HANDzEBYBAL1OTEyMZs2aJY/Ho3fffVfffPONWltbtXv3bj3//POSpBMnTigmJkbR0dH68ssv9frrr3d6uS+++KJaW1v10UcfadeuXRo/fnxgWXFxcYqKilJVVVXQvY7fdeGFFyotLU0vvfSSWltbtW/fPr333nudrqs9jY2N2rp1q37729/qpptu4uE2AAADLkMFAPRK06dPV3x8vH73u99p9erVio6O1pAhQwJPDp09e7aefvpp/f73v9ell16qrKws7d2797yXl5CQoLi4ON15552KiorS7bffrkGDBkmSfvnLX2rjxo167rnnNHz4cI0fP17Hjx9vdz55eXl68sknNW/ePA0dOlRZWVny+XznXdf3zZ07V9Lpy1fT0tJUUFCgUaNGddn8AQC9h83fmWtuAABA4Kcz1q1b1+XzXrlypQYNGhT4qQ0AALoL15wAABBGqqqq9NVXX8nn86myslI7d+7UVVddFeqyAAB9EJehAgAQRhobG7V8+XI1NTXJ5XLpl7/8pS699NJQlwUA6IO4DBUAAAAAYMBlqAAAAAAAA8IiAAAAAMCAsAgAAAAAMCAsAgAAAAAMCIsAAAAAAAPCIgAAAADA4P8B3XYS901vjekAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of the attribution scores\n",
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "campaign_idx = range(150, 250)\n",
    "\n",
    "keras_logistic = model1.get_layer('contributions').get_weights()[0].flatten()[0:n_campaigns]\n",
    "keras_logistic = softmax([keras_logistic]).flatten()\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.bar(range(len(keras_logistic[campaign_idx])), keras_logistic[campaign_idx] )\n",
    "plt.xlabel('Campaign ID')\n",
    "plt.ylabel('Return per impression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribution Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00232201, 0.00312844, 0.00147883, 0.00216226, 0.00149577,\n",
       "       0.00300418, 0.00190545, 0.00242166, 0.00234553, 0.00199198,\n",
       "       0.00304257, 0.00127012, 0.002335  , 0.00233377, 0.00220571,\n",
       "       0.00158466, 0.00407273, 0.00156299, 0.00164922, 0.0021392 ,\n",
       "       0.00383461, 0.00157069, 0.00204161, 0.0024412 , 0.00232036,\n",
       "       0.00318704, 0.00299496, 0.00158254, 0.00310078, 0.00324086,\n",
       "       0.00267555, 0.00246236, 0.00273928, 0.0020281 , 0.00186485,\n",
       "       0.00294264, 0.00267993, 0.00217368, 0.00175291, 0.00324061,\n",
       "       0.00123323, 0.00165512, 0.00385873, 0.00272411, 0.00256467,\n",
       "       0.00149354, 0.0020203 , 0.00237623, 0.00237004, 0.00143968,\n",
       "       0.00261711, 0.00255414, 0.00120577, 0.00233123, 0.00223594,\n",
       "       0.00291015, 0.00227793, 0.00319012, 0.00250513, 0.00295825,\n",
       "       0.00244498, 0.00173654, 0.00287467, 0.00196191, 0.00270316,\n",
       "       0.00283313, 0.00276377, 0.00141506, 0.00198851, 0.002226  ,\n",
       "       0.0022142 , 0.002957  , 0.00237284, 0.00184711, 0.00398447,\n",
       "       0.00290959, 0.00224241, 0.00275927, 0.00195874, 0.00295741,\n",
       "       0.00299836, 0.00259643, 0.00177197, 0.00298333, 0.00153024,\n",
       "       0.00233061, 0.00323939, 0.00231994, 0.00310393, 0.00232224,\n",
       "       0.00149193, 0.00123232, 0.00169259, 0.0020472 , 0.00326036,\n",
       "       0.00184204, 0.00134732, 0.00231196, 0.00207757, 0.00237668,\n",
       "       0.00170854, 0.00265998, 0.0021825 , 0.00165926, 0.00203214,\n",
       "       0.00341749, 0.00180094, 0.00261549, 0.0023284 , 0.00233019,\n",
       "       0.00181426, 0.00276479, 0.00302626, 0.00195142, 0.00193424,\n",
       "       0.00303844, 0.00167702, 0.00090306, 0.00255445, 0.00247164,\n",
       "       0.00150315, 0.00319685, 0.00217567, 0.00219329, 0.00420226,\n",
       "       0.00249244, 0.00409718, 0.00312885, 0.00244662, 0.00180974,\n",
       "       0.0035163 , 0.00200053, 0.0016108 , 0.00168856, 0.00220603,\n",
       "       0.00254028, 0.00133331, 0.00252674, 0.00114928, 0.00219834,\n",
       "       0.00238455, 0.00170947, 0.00265723, 0.00251188, 0.00199954,\n",
       "       0.00379908, 0.00147009, 0.00189812, 0.00239122, 0.0023607 ,\n",
       "       0.00236898, 0.00315252, 0.00288318, 0.00338961, 0.00211765,\n",
       "       0.00194602, 0.0016509 , 0.00229216, 0.00300042, 0.00221119,\n",
       "       0.00303478, 0.00146682, 0.00235859, 0.00338515, 0.00130111,\n",
       "       0.00234187, 0.00187442, 0.00361235, 0.00256929, 0.00097819,\n",
       "       0.00247682, 0.00270893, 0.00281102, 0.00249069, 0.00173842,\n",
       "       0.00236738, 0.00123619, 0.00237686, 0.00155568, 0.00376437,\n",
       "       0.00225509, 0.00157626, 0.00293553, 0.00286035, 0.00127973,\n",
       "       0.00374598, 0.00277151, 0.00114708, 0.00215908, 0.00310834,\n",
       "       0.00303219, 0.00243335, 0.00217646, 0.00314084, 0.0023129 ,\n",
       "       0.00452026, 0.0013286 , 0.00303098, 0.00225342, 0.00234003,\n",
       "       0.00183635, 0.00318136, 0.00136813, 0.00265033, 0.0016096 ,\n",
       "       0.00220908, 0.00155139, 0.00141063, 0.00316888, 0.00231163,\n",
       "       0.00332919, 0.00254331, 0.00260097, 0.00233426, 0.00278758,\n",
       "       0.00273381, 0.0039552 , 0.00281465, 0.00310587, 0.00246425,\n",
       "       0.00317319, 0.00279219, 0.00138498, 0.00270572, 0.00109172,\n",
       "       0.00193507, 0.00159983, 0.00157585, 0.00228629, 0.00267675,\n",
       "       0.00250656, 0.00315556, 0.0031589 , 0.0025433 , 0.00244784,\n",
       "       0.00187343, 0.00219367, 0.00211443, 0.00312527, 0.00289234,\n",
       "       0.00267583, 0.00293342, 0.00320602, 0.0012382 , 0.00130347,\n",
       "       0.00280307, 0.00288124, 0.00226974, 0.00230278, 0.00234222,\n",
       "       0.00280751, 0.00307858, 0.00255496, 0.00296935, 0.00313148,\n",
       "       0.0025567 , 0.00232066, 0.00209749, 0.00311161, 0.00234828,\n",
       "       0.0029249 , 0.00323772, 0.00207685, 0.0032234 , 0.002643  ,\n",
       "       0.00286305, 0.00222984, 0.00212938, 0.00321412, 0.00200127,\n",
       "       0.00253849, 0.00241298, 0.00148454, 0.00376235, 0.00196781,\n",
       "       0.00264133, 0.00183385, 0.0024807 , 0.00217357, 0.0038135 ,\n",
       "       0.00250409, 0.00249679, 0.00253383, 0.0024395 , 0.00260897,\n",
       "       0.00265376, 0.00361372, 0.00298407, 0.0024802 , 0.00301731,\n",
       "       0.00430494, 0.0036944 , 0.00182334, 0.00182351, 0.00269895,\n",
       "       0.00232411, 0.00193989, 0.00330693, 0.00181645, 0.00213645,\n",
       "       0.00109786, 0.00302584, 0.00227838, 0.00228404, 0.00183253,\n",
       "       0.00232951, 0.00220401, 0.00306688, 0.00283744, 0.00297602,\n",
       "       0.00156286, 0.00120439, 0.00325327, 0.00363858, 0.00213099,\n",
       "       0.00364348, 0.00234731, 0.0023761 , 0.001769  , 0.00277138,\n",
       "       0.00267133, 0.00277307, 0.0031343 , 0.00192376, 0.0036406 ,\n",
       "       0.00241911, 0.00278935, 0.00212614, 0.00117821, 0.00342888,\n",
       "       0.00340408, 0.00370145, 0.00220241, 0.00283557, 0.00262768,\n",
       "       0.00242307, 0.00301166, 0.00261338, 0.00342856, 0.00306867,\n",
       "       0.00340587, 0.00322376, 0.00297772, 0.004122  , 0.00233625,\n",
       "       0.00361564, 0.0023431 , 0.00317122, 0.00191535, 0.00272306,\n",
       "       0.00304413, 0.00221179, 0.00260073, 0.00253207, 0.0020155 ,\n",
       "       0.00242819, 0.0029969 , 0.00257213, 0.00257827, 0.00251388,\n",
       "       0.00293931, 0.00270601, 0.00244188, 0.00269488, 0.00319098,\n",
       "       0.00274873, 0.00342024, 0.00263727, 0.00246534, 0.00261477,\n",
       "       0.00251394, 0.00286574, 0.0031204 , 0.00279109, 0.0029329 ,\n",
       "       0.002812  , 0.00284738, 0.00195759, 0.00285859, 0.00282196,\n",
       "       0.00316421, 0.00330945, 0.0030264 , 0.00279666, 0.0028611 ,\n",
       "       0.00224096, 0.0035704 , 0.00231234, 0.00314492, 0.00353599,\n",
       "       0.0031927 , 0.00217528, 0.00208033, 0.00339458, 0.00380206,\n",
       "       0.00270229, 0.00227158, 0.0025748 , 0.00326168, 0.00304329],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"logistic.txt\",keras_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
